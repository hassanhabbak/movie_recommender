# AUTOGENERATED! DO NOT EDIT! File to edit: 00_movies_metadata.ipynb (unless otherwise specified).

__all__ = ['clean_metadata', 'get_adult_feature', 'get_genre_names', 'labelEncoder_genres', 'get_original_language',
           'get_numerical_features', 'get_datetime', 'get_datetime_decade_label', 'get_datetime_recent',
           'lemmatize_stemming', 'preprocess', 'encode_movie_overview', 'get_movie_features']

# Cell
import numpy as np
import pandas as pd
import pandas_profiling
from IPython.display import HTML, Image
from sklearn import preprocessing
from iso_language_codes import language_dictionary
import os
import datetime
import gensim
from gensim.utils import simple_preprocess
from gensim.parsing.preprocessing import STOPWORDS
from nltk.stem import WordNetLemmatizer, SnowballStemmer
from nltk.stem.porter import *
from gensim import corpora, models
import nltk
import umap
import matplotlib.pyplot as plt

# Cell
def clean_metadata(df):
    """Drops certain erroneous rows and duplicates"""
    df = df.drop([35587, 19730])
    df['id'] = pd.to_numeric(df.id, errors='coerce')
    df = df.dropna(subset=['id'])
    df['id'] = df['id'].astype(int)
    df = df.drop_duplicates(subset=['id'], keep=False)
    df = df.drop_duplicates()

    return df.reset_index()

# Cell
def get_adult_feature(df):
    """Cleans the adult column by turning it into boolean. Uses False as default value for others."""
    return df.adult.map({'True': True, 'False': False}).fillna(False).astype(bool)

# Cell
def get_genre_names(df):
    """Returns list of genre Names per movie. Has an override dictionary for correcting some genres."""

    overide = {'Aniplex':'Anime', 'BROSTA TV':'Anime', 'Carousel Productions':'pageants',
          'GoHands':'Anime', 'Mardock Scramble Production Committee':'Anime',
           'Sentai Filmworks':'Anime'}

    return df.genres.apply(lambda x: [e['name'] if e['name'] not in overide else overide[e['name']] for e in eval(x)])

# Cell
def labelEncoder_genres(genres):
    """Create label encoder object from genres"""

    genre_names = np.unique(np.concatenate(genres.values).ravel())

    le = preprocessing.LabelBinarizer()
    vecs = le.fit_transform(genre_names.tolist())

    return le, vecs

# Cell
def get_original_language(df):
    """Returns movie original language. Checks if the code is correct."""
    accepted_ISO = language_dictionary().keys()
    return df.original_language.apply(lambda x: x if x in accepted_ISO else 'NA').astype(str)

# Cell
def get_numerical_features(df):
    """Returns numerical features in the dataset. Sets NA to 0.0."""
    return df[['vote_count', 'vote_average',
                    'runtime', 'popularity']] \
            .apply(lambda x: pd.to_numeric(x, errors='coerce')) \
            .fillna(0.0)

# Cell
def get_datetime(df):
    """Returns movie datetime. Fills NA with 2 years ago. 2 Years is to avoid being considered recent, but also not too far ago."""
    return pd.to_datetime(pd.to_datetime(df['release_date'], errors='coerce') \
               .fillna((datetime.datetime.now() - datetime.timedelta(days=2*365)).date()))

# Cell
def get_datetime_decade_label(d):
    """Returns datetime decade label from datetime"""
    r = d.apply(lambda x: np.floor((datetime.datetime.now().year - (x.year)) / 10.0) if x.date().year > 1930 else 6)
    r = r.rename('decade_label')
    return r

# Cell
def get_datetime_recent(d):
    """Returns datetime boolean for if it was released less than 2 years"""
    r = d.apply(lambda x: True if (datetime.datetime.now() - (x)).days < 2*365 else False)
    r = r.rename('released_recently')
    return r

# Cell
def lemmatize_stemming(text):
    stemmer = SnowballStemmer('english')
    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))

# Cell
def preprocess(text):
    result = []
    for token in gensim.utils.simple_preprocess(text):
        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:
            result.append(lemmatize_stemming(token))
    return result

# Cell
def encode_movie_overview(meta_df):
    """Returns a dictionary of NLP models to embed movie overview"""

    # Tokenize, remove stopwords, lemmatize and stem
    processed = meta_df.overview.astype(str).apply(preprocess)

    # Number of times a word appears in the training set. Drop words fewer than 15
    dictionary = gensim.corpora.Dictionary(processed)
    dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)

    # Bag of words
    bow_corpus = [dictionary.doc2bow(doc) for doc in processed]

    # TFIDF
    tfidf = models.TfidfModel(bow_corpus)
    corpus_tfidf = tfidf[bow_corpus]

    # LDA model of 10 topics
    lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)

    # Produce the topic distribution per document
    vectors = []
    for b in bow_corpus:
        n = np.zeros(10)
        topics = lda_model_tfidf[b]
        for t in topics:
            n[t[0]] = t[1]
        vectors.append(n)

    return {'vectors': vectors, 'dictionary':dictionary,
            'tfidf':tfidf, 'lda':lda_model_tfidf}

# Cell
def get_movie_features(df):

    """Constructs fetures for movies using functions constructed in this module"""

    df = clean_metadata(df)

    dates = get_datetime(df)

    genres = get_genre_names(df)

    le, genre_vecs = labelEncoder_genres(genres)

    genre_df = pd.DataFrame.from_records(genres.apply(lambda x: np.sum(le.transform(x), axis=0) if len(x) > 0 else np.zeros(len(le.classes_))).values)
    genre_df.columns = ['G_'+str(i) for i in range(len(genre_df.columns))]

    df_features=  pd.concat([df['id'].astype(int),
                            get_adult_feature(df),
                            get_numerical_features(df),
                            get_datetime_decade_label(dates),
                            get_datetime_recent(dates)], axis=1)



    return pd.concat([df_features, genre_df], axis=1).set_index('id')